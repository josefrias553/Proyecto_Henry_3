# Arquitectura de Pipeline ELT
## Documento T√©cnico de Dise√±o

---

## 1. Objetivo del Pipeline

### Problema de Negocio
En el contexto empresarial actual, las organizaciones enfrentan la creciente necesidad de consolidar datos dispersos en m√∫ltiples sistemas transaccionales, APIs externas, archivos planos y fuentes no estructuradas. La falta de una vista unificada y confiable de los datos **impide la toma de decisiones estrat√©gicas basadas en evidencia**, genera inconsistencias en reportes, y limita la capacidad anal√≠tica de la organizaci√≥n.

**Dominio de Aplicaci√≥n:** El pipeline se dise√±a para integrar datos de plataformas de alojamientos, incluyendo propiedades, anfitriones, precios, disponibilidad y rese√±as, pudiendo extenderse a otras fuentes transaccionales o de eventos en el futuro.

El pipeline ELT propuesto resuelve este problema mediante:

- **Consolidaci√≥n centralizada** de datos de m√∫ltiples fuentes heterog√©neas
- **Persistencia hist√≥rica** que permite an√°lisis temporal y auditor√≠a
- **Transformaci√≥n desacoplada** que habilita iteraciones r√°pidas sin afectar la extracci√≥n
- **Acceso democratizado** a datos de calidad para equipos de negocio, analytics y ciencia de datos

### Decisiones Habilitadas

Este sistema habilita capacidades anal√≠ticas estrat√©gicas y operacionales:

**Anal√≠tica Estrat√©gica:**
- Identificaci√≥n de patrones de comportamiento de clientes a lo largo del tiempo
- An√°lisis de rentabilidad por producto, regi√≥n, canal de venta
- Proyecciones de demanda basadas en datos hist√≥ricos consolidados
- Evaluaci√≥n de eficiencia operacional y optimizaci√≥n de procesos

**Anal√≠tica Operacional:**
- Monitoreo de KPIs en tiempo casi real
- Detecci√≥n de anomal√≠as en transacciones o comportamiento
- Reporter√≠a regulatoria y compliance
- An√°lisis de calidad de datos y confiabilidad de fuentes

---

## 2. Descripci√≥n de las Etapas ELT

### 2.1 Extract ‚Äî Extracci√≥n

**Objetivo:** Obtener datos de m√∫ltiples fuentes con m√≠nima transformaci√≥n, preservando fidelidad con el origen.

#### Tipos de Fuentes

| Tipo de Fuente | Ejemplos | M√©todo de Extracci√≥n | Frecuencia T√≠pica |
|----------------|----------|----------------------|-------------------|
| **Bases de datos transaccionales** | PostgreSQL, MySQL, SQL Server, Oracle | CDC (Change Data Capture) o Full/Incremental snapshots | Incremental (cada 15-60 min) |
| **Archivos planos** | CSV, JSON, Parquet, XML | API de Object Storage o file watchers | Batch diario/horario |
| **APIs REST** | CRM, ERP externo, servicios de pago | HTTP polling o webhooks | Near real-time o batch |
| **Streaming** | Kafka, event logs, clickstream | Consumidores de streams | Real-time |
| **Web scraping** | Portales p√∫blicos, competencia | Scrapers programados | Batch diario/semanal |

#### Enfoques de Extracci√≥n

**Full Load (Carga Completa):**
- Justificado para tablas peque√±as (< 1M registros) o sin timestamp de modificaci√≥n
- Permite detecci√≥n de deletes impl√≠citos
- Mayor costo computacional y de red

**Incremental Load (Carga Incremental):**
- Basado en columnas de control: `updated_at`, `created_at`, o secuencias incrementales
- Reduce volumen de datos transferidos significativamente
- Requiere gesti√≥n de deletes expl√≠cita (soft deletes o tablas de log)

**Change Data Capture (CDC):**
- Captura cambios directamente del transaction log de la BD origen
- Latencia m√≠nima (segundos a minutos)
- Requiere permisos especiales y herramientas especializadas (Debezium, AWS DMS, Airbyte)

**Near Real-Time:**
- Para decisiones operacionales cr√≠ticas (fraud detection, inventory management)
- Balance entre latencia y costo de infraestructura

#### Principios de Dise√±o en Extracci√≥n

1. **Idempotencia:** Reejecutar una extracci√≥n no debe producir duplicados ni inconsistencias
2. **M√≠nima transformaci√≥n:** Solo tipado b√°sico, sin l√≥gica de negocio
3. **Metadata enriquecida:** Capturar `extracted_at`, `source_system`, `extraction_id` para auditor√≠a
4. **Resiliencia:** Manejo de reconexi√≥n, timeouts, y retry con backoff exponencial
5. **Observabilidad:** M√©tricas de volumen extra√≠do, latencia, y tasa de errores

---

### 2.2 Load ‚Äî Carga

**Objetivo:** Persistir datos crudos en un almacenamiento escalable y de bajo costo, optimizado para escritura masiva.

#### Estrategia de Carga

**Destino:** Data Lake / Lakehouse sobre Object Storage (S3, Azure Data Lake Storage, Google Cloud Storage)

**Formato de Persistencia:**
- **Parquet:** Columnar, compresi√≥n eficiente, compatible con motores anal√≠ticos
- **Delta Lake / Apache Iceberg:** Formatos table con capacidades ACID, time travel, schema evolution
- **JSON/CSV:** Solo para datos semi-estructurados o casos espec√≠ficos

**Patr√≥n de Escritura:**
- **Particionado temporal:** `year=YYYY/month=MM/day=DD/` para facilitar filtrado y retenci√≥n
- **Particionado por fuente:** `source_system=crm/table=customers/`
- **Compresi√≥n:** Snappy o ZSTD seg√∫n balance velocidad/tama√±o

**Modos de Escritura:**

| Modo | Descripci√≥n | Caso de Uso |
|------|-------------|-------------|
| **Append** | Agregar datos sin sobrescribir | Logs, eventos, incremental loads |
| **Overwrite** | Reemplazar partici√≥n completa | Full loads, reprocesos |
| **Merge (Upsert)** | Actualizar registros existentes o insertar nuevos | CDC, actualizaciones incrementales con Delta Lake |

#### Consideraciones de Rendimiento

- **Batch sizing:** Escribir en micro-batches de 100k-1M registros para balance latencia/throughput
- **Compactaci√≥n:** Procesos peri√≥dicos para consolidar archivos peque√±os (evitar "small files problem")
- **Indexing:** Z-ordering o clustering keys en Delta Lake/Iceberg para mejorar query performance

---

### 2.3 Transform ‚Äî Transformaci√≥n

**Objetivo:** Convertir datos crudos en modelos anal√≠ticos consumibles, aplicando l√≥gica de negocio, calidad y conformaci√≥n.

#### Enfoque ELT vs ETL

| Aspecto | ETL (Tradicional) | ELT (Moderno) |
|---------|-------------------|---------------|
| **Transformaci√≥n** | Antes de cargar (en herramienta externa) | Despu√©s de cargar (en el destino) |
| **Escalabilidad** | Limitada por servidor ETL | Escalabilidad horizontal del Lakehouse/DW |
| **Flexibilidad** | R√≠gido, requiere re-extracci√≥n para cambios | Iterativo, re-transformar sin re-extraer |
| **Costo** | Hardware dedicado para ETL | Compute on-demand |

**Adoptamos ELT** porque:
- Aprovecha poder computacional distribuido (Spark, SQL engines)
- Permite auditor√≠a completa manteniendo datos raw
- Facilita reprocesos y correcciones hist√≥ricas
- Desarrollo m√°s √°gil con herramientas como dbt

#### Capas de Transformaci√≥n

La transformaci√≥n se estructura en capas progresivas (detalladas en secci√≥n 3):

1. **Raw ‚Üí Staging:** Estandarizaci√≥n m√≠nima, tipado, deduplicaci√≥n
2. **Staging ‚Üí Core/Intermediate:** Limpieza, normalizaci√≥n, integraci√≥n entre fuentes
3. **Core ‚Üí Gold/Marts:** Modelado dimensional, agregaciones, m√©tricas de negocio

#### Herramientas de Transformaci√≥n

**dbt (data build tool):**
- Transformaciones SQL versionadas en Git
- Testing integrado (unique, not_null, relationships)
- Documentaci√≥n auto-generada
- Lineage visual de dependencias

**Apache Spark:**
- Procesamiento distribuido para grandes vol√∫menes (>TB)
- Soporte para transformaciones complejas en Python/Scala
- Integraci√≥n nativa con Delta Lake

**SQL Engines (Snowflake, BigQuery, Databricks SQL):**
- Transformaciones declarativas SQL
- Escalabilidad autom√°tica
- Costos basados en uso

#### Principios de Transformaci√≥n

1. **Desacople:** Cada capa es independiente, no se salta niveles
2. **Testing:** Cada transformaci√≥n tiene tests de contrato (schema) y calidad
3. **Incrementalidad:** Procesamiento incremental donde sea posible (dbt incremental models)
4. **Reproducibilidad:** Mismos inputs ‚Üí mismos outputs, sin efectos laterales
5. **Documentaci√≥n:** Cada modelo documenta l√≥gica de negocio, owner, y SLA

---

## 3. Definici√≥n de Capas del Data Warehouse

### 3.1 Raw / Staging Layer

**Prop√≥sito:**
Almacenar datos **tal como llegan de la fuente**, sin transformaciones de negocio, actuando como fuente de verdad √∫nica y habilitando auditor√≠a completa.

**Caracter√≠sticas:**

| Aspecto | Especificaci√≥n |
|---------|----------------|
| **Formato** | Parquet, Delta Lake, JSON (seg√∫n origen) |
| **Schema** | Schema-on-read o schema evolution habilitada |
| **Transformaciones permitidas** | Solo tipado b√°sico, deduplicaci√≥n t√©cnica, enriquecimiento metadata |
| **Particionado** | Por fecha de ingesta y fuente |
| **Retenci√≥n** | 90 d√≠as a 2 a√±os seg√∫n compliance y costo |

**Responsabilidades:**

- ‚úÖ Persistencia fiel a la fuente (incluyendo datos "sucios")
- ‚úÖ Metadata de auditor√≠a: `ingestion_timestamp`, `source_file`, `extraction_batch_id`
- ‚úÖ Soporte para reprocesos completos
- ‚úÖ Detecci√≥n de schema drift

**L√≠mites (NO debe hacer):**

- ‚ùå Aplicar l√≥gica de negocio (c√°lculos, categorizaciones)
- ‚ùå Joins entre fuentes
- ‚ùå Filtrado de datos "malos" (excepto duplicados t√©cnicos obvios)

**Ejemplo de Naming:**
```
raw/
‚îú‚îÄ‚îÄ source_system=erp_sap/
‚îÇ   ‚îú‚îÄ‚îÄ table=sales_orders/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ year=2026/month=01/day=21/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ part-00000.parquet
‚îú‚îÄ‚îÄ source_system=api_stripe/
‚îÇ   ‚îî‚îÄ‚îÄ endpoint=payments/
```

---

### 3.2 Core / Intermediate Layer

**Prop√≥sito:**
Aplicar **limpieza, normalizaci√≥n e integraci√≥n** de datos cross-source, generando datasets confiables y reutilizables para m√∫ltiples casos de uso.

**Caracter√≠sticas:**

| Aspecto | Especificaci√≥n |
|---------|----------------|
| **Formato** | Delta Lake / Iceberg (ACID necesario) |
| **Schema** | Fuertemente tipado, con contratos validados |
| **Transformaciones** | Limpieza, deduplicaci√≥n sem√°ntica, conformaci√≥n dimensional |
| **Particionado** | Por fecha de negocio (order_date, transaction_date) |
| **Retenci√≥n** | 2-7 a√±os, seg√∫n necesidades anal√≠ticas |

**Responsabilidades:**

- ‚úÖ **Limpieza de datos:** nulls handling, valores fuera de rango, correcci√≥n de tipos
- ‚úÖ **Deduplicaci√≥n sem√°ntica:** Eliminar duplicados basados en l√≥gica de negocio
- ‚úÖ **Conformaci√≥n:** Estandarizaci√≥n de c√≥digos (country codes, currency codes)
- ‚úÖ **Slowly Changing Dimensions (SCD):** Tracking de cambios hist√≥ricos en dimensiones (Type 2)
- ‚úÖ **Integraci√≥n cross-source:** Joins entre CRM + ERP + logs para crear entidades unificadas
- ‚úÖ **Enriquecimiento:** C√°lculos derivados que son reutilizables (d√≠as desde primera compra, segmentaci√≥n RFM)

**L√≠mites:**

- ‚ùå Agregaciones pesadas (sumas por trimestre, promedios m√≥viles complejos)
- ‚ùå Modelado espec√≠fico para un dashboard (eso va en Gold)

**Ejemplo de Modelos:**

```
core/
‚îú‚îÄ‚îÄ dim_customer (SCD Type 2)
‚îÇ   ‚îú‚îÄ‚îÄ customer_key (surrogate)
‚îÇ   ‚îú‚îÄ‚îÄ customer_id (business key)
‚îÇ   ‚îú‚îÄ‚îÄ email, name, segment
‚îÇ   ‚îú‚îÄ‚îÄ valid_from, valid_to, is_current
‚îú‚îÄ‚îÄ dim_product
‚îú‚îÄ‚îÄ dim_date (pre-generada, 10 a√±os)
‚îî‚îÄ‚îÄ fct_transactions (event-level, no agregado)
    ‚îú‚îÄ‚îÄ transaction_id
    ‚îú‚îÄ‚îÄ customer_key (FK)
    ‚îú‚îÄ‚îÄ product_key (FK)
    ‚îú‚îÄ‚îÄ amount, quantity, discount
    ‚îî‚îÄ‚îÄ transaction_date
```

---

### 3.3 Gold / Consumption Layer (Data Marts)

**Prop√≥sito:**
Proveer **modelos listos para consumo**, optimizados para casos de uso espec√≠ficos (BI, reporting, ML), con agregaciones pre-calculadas y l√≥gica de negocio final.

**Caracter√≠sticas:**

| Aspecto | Especificaci√≥n |
|---------|----------------|
| **Formato** | Vistas materializadas, tablas agregadas, cach√©s |
| **Schema** | Orientado a negocio, nombres no-t√©cnicos |
| **Transformaciones** | Agregaciones, window functions, m√©tricas calculadas |
| **Optimizaci√≥n** | Indexes, clustering, caching seg√∫n herramienta |
| **Retenci√≥n** | Seg√∫n SLA de reporter√≠a (usualmente 1-3 a√±os) |

**Responsabilidades:**

- ‚úÖ **Agregaciones pre-calculadas:** Ventas por mes/regi√≥n, m√©tricas rolling de 7/30/90 d√≠as
- ‚úÖ **M√©tricas de negocio:** LTV, AOV, churn rate, conversion funnels
- ‚úÖ **Star/Snowflake schemas** optimizados para herramientas BI espec√≠ficas
- ‚úÖ **Denormalizaci√≥n estrat√©gica:** Para mejorar query performance
- ‚úÖ **Row-level security (RLS):** Filtros de acceso por usuario/rol

**L√≠mites:**

- ‚ùå Almacenar datos granulares que ya est√°n en Core (evitar duplicaci√≥n)
- ‚ùå L√≥gica de transformaci√≥n base (ya debe estar en Core)

**Ejemplos de Marts:**

```
gold/
‚îú‚îÄ‚îÄ mart_sales_performance
‚îÇ   ‚îú‚îÄ‚îÄ M√©tricas mensuales por producto/regi√≥n
‚îÇ   ‚îú‚îÄ‚îÄ YoY growth, trends
‚îú‚îÄ‚îÄ mart_customer_360
‚îÇ   ‚îú‚îÄ‚îÄ Vista unificada de cliente (transacciones + soporte + marketing)
‚îÇ   ‚îú‚îÄ‚îÄ Segmentaci√≥n, LTV, engagement score
‚îú‚îÄ‚îÄ mart_inventory_optimization
‚îî‚îÄ‚îÄ mart_executive_dashboard
```

**Consumidores T√≠picos:**

- Dashboards de BI (Tableau, Power BI, Looker)
- APIs de reporter√≠a
- Modelos de ML (feature engineering puede partir de Gold)
- Exportes para reguladores

---

## 4. Diagrama T√©cnico de Arquitectura

### Descripci√≥n Conceptual del Flujo de Datos

A continuaci√≥n se describe la arquitectura l√≥gica del sistema, que puede ser plasmada visualmente en herramientas como Draw.io, Lucidchart o arquitecture diagrams tools.

![alt text](img\image2.png)

### Componentes Detallados

#### **1. Data Sources (Fuentes de Datos)**

| Fuente | Descripci√≥n | M√©todo de Acceso |
|--------|-------------|------------------|
| **OLTP Databases** | Bases transaccionales (PostgreSQL, MySQL, SQL Server, Oracle) | CDC, JDBC connection |
| **External APIs** | CRM (Salesforce), Payment gateways (Stripe), Ads platforms | REST/GraphQL clients |
| **File Storage** | Data dumps, exports legacy, partner files | S3/ADLS API, SFTP |
| **Event Streams** | Clickstream, IoT sensors, application logs | Kafka consumers |
| **Web Scraping** | Datos p√∫blicos de competencia, portales regulatorios | Custom scrapers (Scrapy, Selenium) |

#### **2. Extraction Layer**

| Herramienta | Prop√≥sito | Ventajas |
|-------------|-----------|----------|
| **Debezium / AWS DMS** | CDC para bases de datos | Latencia baja, captura deletes |
| **Airbyte / Fivetran** | Conectores pre-built para SaaS APIs | Reducci√≥n de boilerplate, mantenimiento |
| **Python/Spark Scripts** | Extractores custom | Flexibilidad total |
| **Kafka Connect** | Ingesta de streams | Escalabilidad horizontal, fault-tolerance |

#### **3. Data Lake / Lakehouse (Object Storage)**

**Tecnolog√≠a:** S3, ADLS Gen2, GCS con formato Delta Lake / Apache Iceberg

**Capacidades clave:**
- ‚úÖ ACID transactions
- ‚úÖ Time travel (consultar versi√≥n hist√≥rica de datos)
- ‚úÖ Schema evolution
- ‚úÖ Costo bajo (~$0.023/GB/mes en S3 Standard)

#### **4. Transformation Engine**

| Herramienta | Caso de Uso | Fortalezas |
|-------------|-------------|------------|
| **dbt** | Transformaciones SQL est√°ndar | Version control, testing, documentaci√≥n |
| **Apache Spark** | Transformaciones complejas, grandes vol√∫menes | Escalabilidad, UDFs en Python/Scala |
| **Orchestrator (Airflow/Dagster)** | Coordinaci√≥n de pipelines | Retry logic, sensores, lineage visual |

#### **5. Consumption Layer**

| Consumer | Latencia Aceptable | Patr√≥n de Acceso |
|----------|-------------------|------------------|
| **BI Dashboards** | Minutos a horas | Interactive queries, caching |
| **APIs** | Segundos | Pre-computed aggregates, caching Redis |
| **ML Training** | Batch diario/semanal | Bulk exports, Parquet snapshots |
| **Reports** | Batch nocturno | Scheduled exports (PDF, Excel) |

---

## 5. Justificaci√≥n de Herramientas y Tecnolog√≠as

### Criterios de Selecci√≥n

| Criterio | Peso | Justificaci√≥n |
|----------|------|---------------|
| **Escalabilidad horizontal** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | El sistema debe crecer de GB a TB a PB sin redise√±o |
| **Costo Total de Ownership (TCO)** | ‚≠ê‚≠ê‚≠ê‚≠ê | Balance entre costo de infraestructura y productividad del equipo |
| **Facilidad de integraci√≥n** | ‚≠ê‚≠ê‚≠ê‚≠ê | Ecosistema compatible, APIs est√°ndar |
| **Community & Soporte** | ‚≠ê‚≠ê‚≠ê | Documentaci√≥n, troubleshooting, talent availability |
| **Vendor Lock-in** | ‚≠ê‚≠ê‚≠ê | Preferencia por tecnolog√≠as open-source o multi-cloud |

---

### Stack T√©cnico Propuesto

#### **Storage Layer**

**Tecnolog√≠a:** Object Storage (S3 / Azure Data Lake Storage / GCS) + Delta Lake

| Aspecto | Justificaci√≥n |
|---------|---------------|
| **Escalabilidad** | Petabytes sin l√≠mite pr√°ctico, escalabilidad autom√°tica |
| **Costo** | 10-50x m√°s barato que bases de datos tradicionales para datos fr√≠os |
| **Compatibilidad** | Compatible con Spark, dbt, Trino, Presto, Athena, BigQuery (external tables) |
| **ACID con Delta Lake** | Transacciones garantizadas, time travel, schema versioning |
| **Separaci√≥n compute-storage** | M√∫ltiples motores pueden leer/escribir sin duplicar datos |

**Alternativa:** Apache Iceberg (mismas ventajas, mayor adopci√≥n en Snowflake/Databricks ecosystems)

---

#### **Transformation Layer**

**Tecnolog√≠a Principal:** dbt (data build tool)

| Aspecto | Justificaci√≥n |
|---------|---------------|
| **SQL-first** | 80% de transformaciones son SQL puro, accesible para analistas |
| **Version control** | Transformaciones en Git, code review, CI/CD integrado |
| **Testing integrado** | Tests de schema, unicidad, relaciones, custom tests |
| **Documentaci√≥n auto-generada** | Lineage graph, column descriptions, metadata catalogs |
| **Incrementalidad** | Procesamiento incremental nativo reduce costos 10-100x |
| **Ecosistema** | Compatible con Snowflake, BigQuery, Databricks, Redshift, Spark |

**Tecnolog√≠a Complementaria:** Apache Spark (PySpark)

| Aspecto | Justificaci√≥n |
|---------|---------------|
| **C√°lculos complejos** | ML feature engineering, graph processing, iterative algorithms |
| **Grandes vol√∫menes** | Procesamiento distribuido de TB en minutos (vs horas en SQL tradicional) |
| **UDFs custom** | L√≥gica no expresable en SQL (parsing, ML inference inline) |
| **Integraci√≥n con Delta Lake** | API nativa para merge, optimize, vacuum |

---

#### **Orchestration**

**Tecnolog√≠a Seleccionada:** Apache Airflow

**Apache Airflow** ser√° utilizado como orquestador del pipeline ELT en fases posteriores de implementaci√≥n. Airflow permite coordinar la ejecuci√≥n de tareas de extracci√≥n, transformaci√≥n y validaci√≥n mediante DAGs (Directed Acyclic Graphs), proporcionando:

| Aspecto | Justificaci√≥n |
|---------|---------------|
| **DAG-based scheduling** | Dependencias complejas manejadas declarativamente |
| **Retry logic** | Manejo autom√°tico de fallos transitorios |
| **Monitoring** | Alertas, SLA tracking, visualizaci√≥n de cuellos de botella |
| **Extensibilidad** | Operadores custom para cualquier herramienta |
| **Madurez** | Gran comunidad, amplia adopci√≥n enterprise, muchos operators pre-built |

**Alternativas evaluadas:**

| Herramienta | Fortalezas | Debilidades |
|-------------|------------|-------------|
| **Airflow** | Maduro, gran community, muchos operators | Curva de aprendizaje, UI legacy |
| **Dagster** | Modern, data-aware, testing f√°cil | Menos maduro, menos operators |
| **Prefect** | H√≠brido (cloud + local), UX excelente | Menos adopci√≥n enterprise |

**CI/CD:** **GitHub Actions** ser√° utilizado para automatizar pipelines de integraci√≥n y despliegue continuo, incluyendo tests de dbt, validaciones de calidad de c√≥digo, y despliegues automatizados de transformaciones.

---

#### **Compute Engine**

**Opci√≥n A:** Databricks (Lakehouse Platform)

| Aspecto | Beneficio |
|---------|----------|
| **Unified platform** | Spark + Delta Lake + dbt + notebooks + ML en una plataforma |
| **Auto-scaling** | Clusters escalan autom√°ticamente seg√∫n carga |
| **Unity Catalog** | Governance, lineage, access control integrado |
| **Photon engine** | Queries vectorizadas, 3-5x m√°s r√°pidas que Spark est√°ndar |

**Opci√≥n B:** Snowflake (Cloud Data Warehouse)

| Aspecto | Beneficio |
|---------|----------|
| **Zero management** | No hay clusters que configurar, escalabilidad autom√°tica |
| **Query performance** | Optimizaciones autom√°ticas, resultados cacheados |
| **Data sharing** | Cross-company data sharing sin ETL |
| **Time travel** | Recuperar datos de hasta 90 d√≠as atr√°s |

**Opci√≥n C:** Self-managed Spark on Kubernetes

| Aspecto | Beneficio |
|---------|----------|
| **Costo** | M√°s barato en escala (no markup de vendor) |
| **Control total** | Customizaci√≥n completa de configuraci√≥n |
| **Multi-cloud** | Portabilidad entre AWS/Azure/GCP |

**Debilidades:** Requiere expertise DevOps, overhead de mantenimiento

---

#### **BI & Analytics**

**Recomendaci√≥n:** Herramienta seg√∫n perfil de usuario

| Usuario | Herramienta | Justificaci√≥n |
|---------|-------------|---------------|
| **Ejecutivos** | Tableau / Power BI | Dashboards visuales, interactividad |
| **Analistas** | Looker / Metabase | Self-service, SQL lightweight |
| **Data Scientists** | Jupyter / Hex / Deepnote | Notebooks, Python/R, colaboraci√≥n |
| **Developers** | APIs (GraphQL/REST) | Integraci√≥n con aplicaciones |

---

#### **Data Catalog & Governance**

**Tecnolog√≠a:** Unity Catalog (Databricks) / Datahub (Open Source)

| Aspecto | Beneficio |
|---------|----------|
| **Discovery** | Search de datasets por keywords, tags, owners |
| **Lineage** | Visualizaci√≥n de dependencias tabla‚Üítransformaci√≥n‚Üídashboard |
| **Access control** | RBAC, attribute-based access, PII masking |
| **Metadata management** | Descriptions, SLAs, data quality scores |

---

### Consideraciones de Escalabilidad

| Volumen de Datos | Latencia de Procesamiento | Arquitectura Recomendada |
|------------------|---------------------------|--------------------------|
| **< 100 GB** | Batch diario | PostgreSQL + dbt Cloud + Metabase |
| **100 GB - 10 TB** | Batch horario | Snowflake/BigQuery + dbt + Looker |
| **10 TB - 1 PB** | Batch cada 15-60 min | Databricks + Delta Lake + Spark |
| **> 1 PB** | Streaming + batch | Lakehouse multi-layer + Kafka + Spark Streaming |

---

## 6. Identificaci√≥n y An√°lisis de Fuentes de Datos

### Metodolog√≠a de An√°lisis

Para cada pregunta de negocio, se realiza un an√°lisis inverso:

1. **Definir la m√©trica o insight requerido**
2. **Identificar las entidades de negocio involucradas** (clientes, productos, transacciones)
3. **Mapear a fuentes de datos t√©cnicas** (tablas, APIs, archivos)
4. **Evaluar calidad y confiabilidad**
5. **Determinar frecuencia de actualizaci√≥n necesaria**

---

### Preguntas de Negocio y Fuentes Asociadas

#### **Pregunta 1: ¬øCu√°l es el comportamiento de compra de clientes a lo largo del tiempo?**

**Fuentes Requeridas:**

| Fuente | Datos Provistos | Tipo | Frecuencia |
|--------|----------------|------|-----------|
| **ERP (SAP/Oracle)** | Transacciones de venta: order_id, customer_id, product_id, amount, quantity, date | Base de datos transaccional | Incremental (CDC cada 15 min) |
| **CRM (Salesforce)** | Informaci√≥n de cliente: customer_id, segment, lifetime_value, first_purchase_date | API REST | Batch diario |
| **Web Analytics (Google Analytics)** | Clickstream: session_id, customer_id, page_views, events, timestamps | API / BigQuery export | Batch diario |
| **Loyalty Program DB** | Puntos acumulados, tier, redemptions | Base de datos interna | Incremental |

**Relaci√≥n Fuente ‚Üí M√©trica:**
- `dim_customer` (de CRM + ERP) ‚Üí Segmentaci√≥n
- `fct_transactions` (de ERP) ‚Üí Frecuencia, recencia, monto
- `fct_web_events` (de Analytics) ‚Üí Journey pre-compra

**Consideraciones de Calidad:**
- ‚ö†Ô∏è `customer_id` puede no estar linkeado entre web y ERP si no hay login ‚Üí requiere identity resolution
- ‚úÖ ERP es fuente de verdad para transacciones finales
- ‚ö†Ô∏è CRM puede tener desfase de 24h respecto a ERP

---

#### **Pregunta 2: ¬øQu√© productos tienen mejor margen de rentabilidad por regi√≥n?**

**Fuentes Requeridas:**

| Fuente | Datos Provistos | Tipo | Frecuencia |
|--------|----------------|------|-----------|
| **ERP - Sales Module** | Ventas por producto/regi√≥n: revenue, units_sold | DB transaccional | Incremental |
| **ERP - Inventory Module** | Costos de producto: product_id, cogs (cost of goods sold) | DB transaccional | Batch diario |
| **Logistics System** | Costos de env√≠o por regi√≥n | API / CSV exports | Batch semanal |
| **Master Data (MDM)** | Jerarqu√≠as de producto, cat√°logo de regiones | CSV / DB | Full load semanal |

**Relaci√≥n Fuente ‚Üí M√©trica:**
- `fct_sales` ‚Üí Revenue por producto/regi√≥n
- `dim_product` ‚Üí Categor√≠as, jerarqu√≠as, COGS
- `dim_geography` ‚Üí Regiones, pa√≠ses, costos log√≠sticos
- **M√©trica derivada:** `gross_margin = (revenue - cogs - shipping_cost) / revenue`

**Consideraciones de Calidad:**
- ‚úÖ COGS es confiable si el ERP est√° bien configurado
- ‚ö†Ô∏è Costos de env√≠o pueden estar agregados a nivel pa√≠s, no regi√≥n espec√≠fica
- ‚ö†Ô∏è Productos sin `cogs` en MDM ‚Üí requiere imputaci√≥n o exclusi√≥n

---

#### **Pregunta 3: ¬øC√≥mo se compara nuestro pricing vs. competencia?**

**Fuentes Requeridas:**

| Fuente | Datos Provistos | Tipo | Frecuencia |
|--------|----------------|------|-----------|
| **ERP - Pricing Module** | Precios internos: product_id, price, effective_date | DB transaccional | Incremental |
| **Web Scraping - Competidores** | Precios de competencia: competitor, product (matched), price, scraped_at | Web scraping (custom) | Batch diario |
| **Market Data Provider (externo)** | √çndices de mercado, precios sugeridos | API REST | Batch semanal |
| **MDM** | Product matching: sku_interno ‚Üî competitor_sku | Manual curation / ML matching | Full load mensual |

**Relaci√≥n Fuente ‚Üí M√©trica:**
- `dim_product_pricing` ‚Üí Hist√≥rico de precios internos
- `fct_competitor_pricing` ‚Üí Scraping agregado
- **M√©trica derivada:** `price_index = our_price / avg_competitor_price`

**Consideraciones de Calidad:**
- ‚ö†Ô∏è Web scraping puede fallar si sitios cambian estructura HTML
- ‚ö†Ô∏è Product matching entre SKUs internos y externos es complejo ‚Üí requiere fuzzy matching o ML
- ‚úÖ Scraping debe respetar `robots.txt` y t√©rminos de servicio
- üîí Legal: validar compliance antes de scrapear competencia

---

#### **Pregunta 4: ¬øCu√°l es la tasa de churn de clientes y factores asociados?**

**Fuentes Requeridas:**

| Fuente | Datos Provistos | Tipo | Frecuencia |
|--------|----------------|------|-----------|
| **CRM - Customer DB** | Customer profile, segment, status (active/churned) | DB / API | Incremental |
| **Subscription System** | Subscriptions: customer_id, start_date, end_date, plan, payment_status | DB transaccional | CDC |
| **Support Tickets** | Tickets: customer_id, category, resolution_time, sentiment | DB transaccional | Incremental |
| **Email Marketing Platform** | Engagement: customer_id, email_opens, clicks, unsubscribes | API | Batch diario |
| **Payment Gateway (Stripe)** | Payment failures, retry attempts | Webhook ‚Üí Kafka | Real-time |

**Relaci√≥n Fuente ‚Üí M√©trica:**
- `dim_customer` ‚Üí Atributos demogr√°ficos, firmogr√°ficos
- `fct_subscriptions` ‚Üí Lifecycle de suscripci√≥n, churn events
- `fct_support` ‚Üí Indicadores de insatisfacci√≥n
- `fct_engagement` ‚Üí Engagement score
- **M√©trica derivada:** `churn_rate = churned_customers / total_customers (monthly cohorts)`

**Consideraciones de Calidad:**
- ‚úÖ Subscription system es fuente de verdad para churn
- ‚ö†Ô∏è Definici√≥n de churn puede variar: cancelaci√≥n expl√≠cita vs. inactividad vs. no pago
- ‚ö†Ô∏è Support tickets pueden tener `customer_id` null si usuario no estaba logueado ‚Üí linking manual o por email

---

#### **Pregunta 5: ¬øCu√°l es la eficiencia operacional de nuestros centros de distribuci√≥n?**

**Fuentes Requeridas:**

| Fuente | Datos Provistos | Tipo | Frecuencia |
|--------|----------------|------|-----------|
| **Warehouse Management System (WMS)** | Order fulfillment: order_id, warehouse_id, picked_at, packed_at, shipped_at | DB transaccional | Incremental |
| **IoT Sensors** | Equipment uptime, temperature, alerts | MQTT / Kafka | Real-time |
| **HR System** | Staffing levels, shifts, labor hours | API / CSV | Batch diario |
| **Transportation Management System** | Delivery times, carrier performance | DB transaccional | Incremental |

**Relaci√≥n Fuente ‚Üí M√©trica:**
- `fct_fulfillment` ‚Üí Tiempo desde order ‚Üí ship, error rates
- `fct_equipment` ‚Üí Downtime por warehouse
- `dim_warehouse` ‚Üí Capacidad, ubicaci√≥n
- **M√©trica derivada:** `efficiency = orders_shipped / (labor_hours + equipment_downtime_penalty)`

**Consideraciones de Calidad:**
- ‚úÖ WMS timestamps son confiables si hay SLA de registro
- ‚ö†Ô∏è IoT sensors pueden tener gaps por connectivity issues ‚Üí requiere interpolation
- ‚ö†Ô∏è Staffing data puede estar en diferentes zonas horarias ‚Üí normalizaci√≥n cr√≠tica

---

### Evaluaci√≥n de Confiabilidad de Fuentes

| Fuente | Confiabilidad | Justificaci√≥n | Mitigaci√≥n de Riesgos |
|--------|---------------|---------------|----------------------|
| **ERP (SAP/Oracle)** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Alta | Sistema de record, transacciones ACID | Monitoreo de schema changes |
| **CRM (Salesforce)** | ‚≠ê‚≠ê‚≠ê‚≠ê Alta | Datos curados por sales team | Validar contra ERP para customer_id |
| **Web Scraping** | ‚≠ê‚≠ê Baja | Sujeto a cambios de HTML, bloqueos | Alertas de fallo, fallback a fuentes alternativas |
| **APIs Externas** | ‚≠ê‚≠ê‚≠ê Media | Depende de SLA del proveedor | Rate limiting handling, caching |
| **IoT Sensors** | ‚≠ê‚≠ê‚≠ê Media | Ruido, connectivity gaps | Outlier detection, interpolation |
| **Archivos CSV manuales** | ‚≠ê‚≠ê Baja | Errores humanos, formatos inconsistentes | Schema validation en ingesta, alertas |

---

### Matriz de Valor Anal√≠tico

| Fuente | Costo de Integraci√≥n | Frecuencia de Uso | Valor de Negocio | Prioridad |
|--------|----------------------|-------------------|------------------|-----------|
| **ERP Transactions** | Alto (CDC setup) | Diario | Cr√≠tico | **P0** |
| **CRM Data** | Medio (API estable) | Diario | Alto | **P0** |
| **Web Analytics** | Bajo (export nativo) | Diario | Alto | **P1** |
| **Competitor Pricing (scraping)** | Alto (custom, fr√°gil) | Semanal | Medio | **P2** |
| **IoT Sensors** | Alto (streaming setup) | Real-time | Medio (operacional) | **P2** |
| **Social Media APIs** | Medio | Diario | Bajo (nice-to-have) | **P3** |

**Recomendaci√≥n:** Comenzar con fuentes P0 (ERP, CRM), validar pipeline, luego iterar con P1-P2.

---

## 7. Consideraciones de Implementaci√≥n Futura

> [!NOTE]
> Los siguientes temas est√°n **fuera de alcance** en esta fase de dise√±o, pero deben ser considerados en fases posteriores de implementaci√≥n.

### 7.1 Data Quality & Observability

**Frameworks a considerar:**
- **Great Expectations:** Data testing framework (asserts on data)
- **Monte Carlo / Datadog:** Anomaly detection, lineage, alerting
- **dbt tests:** Contratos de schema, business rules

**M√©tricas clave:**
- Freshness (SLA de actualizaci√≥n)
- Completeness (% nulls en columnas cr√≠ticas)
- Accuracy (validaci√≥n contra fuente de verdad)
- Consistency (joins exitosos entre tablas)

---

### 7.2 Security & Compliance

**GDPR / CCPA:**
- Right to erasure ‚Üí hard deletes en Lakehouse (Delta Lake GDPR compliance)
- Data minimization ‚Üí no almacenar PII innecesario
- Encryption at rest (S3 KMS) y in transit (TLS)

**Access Control:**
- RBAC en Data Catalog
- Column-level masking para PII
- Audit logs de accesos

---

### 7.3 Cost Optimization

**Estrategias:**
- Lifecycle policies en S3 (Standard ‚Üí IA ‚Üí Glacier)
- Partitioning inteligente para evitar full scans
- Spot instances para jobs de Spark no cr√≠ticos
- Query result caching en Snowflake/BigQuery

**Monitoreo:**
- Cost attribution por equipo/proyecto
- Alertas de budget overruns

---

### 7.4 Disaster Recovery

**Backups:**
- Snapshots de Delta Lake (time travel integrado)
- Cross-region replication de S3 para datos cr√≠ticos

**RPO/RTO:**
- Recovery Point Objective: m√°ximo 1 d√≠a de p√©rdida de datos
- Recovery Time Objective: restauraci√≥n en < 4 horas

---

## 8. Conclusiones y Pr√≥ximos Pasos

### Resumen Ejecutivo

Este documento define la arquitectura base de un pipeline ELT moderno que:

‚úÖ **Escala horizontalmente** de gigabytes a petabytes sin redise√±o arquitect√≥nico  
‚úÖ **Separa responsabilidades** en capas claras (Raw ‚Üí Core ‚Üí Gold)  
‚úÖ **Habilita iteraci√≥n r√°pida** mediante ELT (transformar sin re-extraer)  
‚úÖ **Garantiza auditor√≠a completa** preservando datos crudos  
‚úÖ **Soporta m√∫ltiples consumidores** (BI, ML, APIs) desde Gold layer  

### Decisiones Arquitect√≥nicas Clave

| Decisi√≥n | Justificaci√≥n |
|----------|---------------|
| **ELT sobre ETL** | Aprovecha compute distribuido del Lakehouse, flexibilidad de reprocesos |
| **Delta Lake / Iceberg** | ACID transactions, time travel, schema evolution en Object Storage barato |
| **Capas Raw-Core-Gold** | Separaci√≥n de concerns, reutilizaci√≥n, auditor√≠a |
| **dbt como transformation engine** | Testing integrado, version control, SQL-first para democratizaci√≥n |
| **Orchestration desacoplada** | Orquestador (Airflow/Dagster) coordina pero no ejecuta transformaciones |

### Riesgos y Mitigaciones

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|--------------|---------|------------|
| **Crecimiento de volumen no anticipado** | Media | Alto | Arquitectura cloud-native con auto-scaling |
| **Schema drift en fuentes** | Alta | Medio | Schema evolution en Delta Lake, alertas de cambios |
| **Calidad de datos en fuentes externas** | Alta | Alto | Data quality tests en Staging, alertas, fallbacks |
| **Vendor lock-in** | Baja | Medio | Preferencia por stacks open-source (Spark, dbt, Iceberg) |

### Roadmap Sugerido

#### **Fase 1: MVP (Mes 1-2)**
- ‚úÖ Setup de infraestructura base (S3 + Delta Lake)
- ‚úÖ Integraci√≥n de 2-3 fuentes prioritarias (ERP, CRM)
- ‚úÖ Implementaci√≥n de capas Raw y Core
- ‚úÖ Dashboard b√°sico de monitoreo de pipeline

#### **Fase 2: Producci√≥n (Mes 3-4)**
- ‚úÖ Integraci√≥n de fuentes restantes (P1-P2)
- ‚úÖ Implementaci√≥n de Gold layer y primeros marts
- ‚úÖ Orquestaci√≥n con Airflow/Dagster
- ‚úÖ Primeros dashboards de BI conectados

#### **Fase 3: Madurez (Mes 5-6)**
- ‚úÖ Data quality framework (Great Expectations)
- ‚úÖ Data Catalog y lineage (Datahub)
- ‚úÖ Incrementalidad en dbt models
- ‚úÖ Cost optimization y performance tuning

#### **Fase 4: Advanced Analytics (Mes 7+)**
- ‚úÖ Feature engineering para ML
- ‚úÖ Real-time streaming layer (Kafka ‚Üí Delta Live Tables)
- ‚úÖ Advanced governance (PII masking, GDPR compliance)

---

## Anexos

### Glosario T√©cnico

| T√©rmino | Definici√≥n |
|---------|------------|
| **CDC (Change Data Capture)** | T√©cnica para capturar cambios incrementales de una base de datos mediante lectura del transaction log |
| **Delta Lake** | Storage layer open-source que provee ACID transactions sobre data lakes (Parquet) |
| **ELT** | Extract-Load-Transform: cargar datos crudos primero, transformar despu√©s en el destino |
| **Lakehouse** | Arquitectura que combina flexibilidad del Data Lake con estructura del Data Warehouse |
| **SCD Type 2** | Slowly Changing Dimension Type 2: tracking de cambios hist√≥ricos con validez temporal |
| **Idempotencia** | Propiedad de una operaci√≥n que produce el mismo resultado si se ejecuta m√∫ltiples veces |

### Referencias

- [Delta Lake Documentation](https://docs.delta.io/)
- [dbt Best Practices](https://docs.getdbt.com/guides/best-practices)
- [Databricks Lakehouse Architecture](https://www.databricks.com/product/data-lakehouse)
- [Kimball Dimensional Modeling](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/)
- [Great Expectations Documentation](https://docs.greatexpectations.io/)

---

**Documento creado por:** Ingeniero Jose David Frias 
**Versi√≥n:** 1.0  
**Fecha:** Enero 2026
